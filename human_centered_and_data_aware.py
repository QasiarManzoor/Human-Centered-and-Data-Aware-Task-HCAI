# -*- coding: utf-8 -*-
"""Human-Centered and Data-Aware.ipynb

Automatically generated by Colab.

"""

import os
import random
import numpy as np
import matplotlib.pyplot as plt

from PIL import Image

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, random_split
from torchvision import datasets, transforms
import torchvision.models as tv_models

import timm

from sklearn.metrics import classification_report, confusion_matrix
import shap
from lime import lime_image
from skimage.segmentation import mark_boundaries

def seed_everything(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = False
    torch.backends.cudnn.benchmark = True

seed_everything(42)

device = "cuda" if torch.cuda.is_available() else "cpu"
print("Device:", device)

DATA_ROOT = "/kaggle/input/brisc2025/brisc2025"  # <-- CHANGE THIS
print("Top-level:", os.listdir(DATA_ROOT)[:30])

import os

DATA_ROOT = "/kaggle/input/brisc2025/brisc2025"

CLS_ROOT = os.path.join(DATA_ROOT, "classification_task")
SEG_ROOT = os.path.join(DATA_ROOT, "segmentation_task")

print("CLS_ROOT:", CLS_ROOT, os.listdir(CLS_ROOT))
print("SEG_ROOT:", SEG_ROOT, os.listdir(SEG_ROOT))

import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
import cv2

CLS_CLASSES = ["glioma", "meningioma", "no_tumor", "pituitary"]
CLS_TO_ID = {c:i for i,c in enumerate(CLS_CLASSES)}

def collect_classification_samples(root, split="train"):
    base = os.path.join(root, split)
    samples = []
    for cls in CLS_CLASSES:
        cdir = os.path.join(base, cls)
        if not os.path.isdir(cdir):
            continue
        for fn in os.listdir(cdir):
            if fn.lower().endswith((".png",".jpg",".jpeg")):
                samples.append((os.path.join(cdir, fn), CLS_TO_ID[cls]))
    return samples

class BRISCClassificationDataset(Dataset):
    def __init__(self, samples, img_size=224):
        self.samples = samples
        self.img_size = img_size

    def __len__(self): return len(self.samples)

    def __getitem__(self, idx):
        path, y = self.samples[idx]
        img = cv2.imread(path, cv2.IMREAD_COLOR)
        if img is None:
            raise FileNotFoundError(path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, (self.img_size, self.img_size)).astype(np.float32) / 255.0
        x = torch.from_numpy(img).permute(2,0,1).float()  # (3,H,W)
        return x, torch.tensor(y, dtype=torch.long)

cls_train_samples = collect_classification_samples(CLS_ROOT, "train")
print("Classification train samples:", len(cls_train_samples))

from pathlib import Path

def list_images(root):
    exts = {".png",".jpg",".jpeg"}
    return [p for p in Path(root).rglob("*") if p.suffix.lower() in exts]

def is_mask_like(path: Path):
    name = path.name.lower()
    parent = str(path.parent).lower()
    # common mask indicators
    return ("mask" in name) or ("seg" in name) or ("gt" in name) or ("label" in name) or ("mask" in parent) or ("labels" in parent)

def build_seg_pairs(seg_root, split="train"):
    base = os.path.join(seg_root, split)
    all_imgs = list_images(base)

    # split into likely masks vs likely images
    masks = [p for p in all_imgs if is_mask_like(p)]
    imgs  = [p for p in all_imgs if not is_mask_like(p)]

    # index masks by stem for matching
    mask_by_stem = {}
    for m in masks:
        mask_by_stem[m.stem] = str(m)

    pairs = []
    for im in imgs:
        # try exact stem match
        if im.stem in mask_by_stem:
            pairs.append((str(im), mask_by_stem[im.stem]))
            continue
        # try relaxed match (some datasets add suffixes)
        # find any mask stem that contains image stem or vice versa
        hit = None
        for ms, mp in mask_by_stem.items():
            if im.stem in ms or ms in im.stem:
                hit = mp
                break
        if hit:
            pairs.append((str(im), hit))

    return pairs, len(imgs), len(masks)

seg_train_pairs, n_imgs, n_masks = build_seg_pairs(SEG_ROOT, "train")
print("Seg train images found:", n_imgs)
print("Seg train masks found:", n_masks)
print("Seg pairs matched:", len(seg_train_pairs))
print("Example pair:", seg_train_pairs[0] if len(seg_train_pairs)>0 else None)

class BRISCSegmentationDataset(Dataset):
    def __init__(self, pairs, img_size=256):
        self.pairs = pairs
        self.img_size = img_size

        # ADD THIS: use same normalization as classification (ImageNet stats)
        self.normalize = T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225))

    def __len__(self):
        return len(self.pairs)

    def __getitem__(self, idx):
        img_path, mask_path = self.pairs[idx]

        img = cv2.imread(img_path, cv2.IMREAD_COLOR)
        if img is None:
            raise FileNotFoundError(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, (self.img_size, self.img_size)).astype(np.float32) / 255.0

        x = torch.from_numpy(img).permute(2,0,1).float()  # (3,H,W)

        # ADD THIS: normalize image tensor (same as classification)
        x = self.normalize(x)

        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        if mask is None:
            raise FileNotFoundError(mask_path)
        mask = cv2.resize(mask, (self.img_size, self.img_size), interpolation=cv2.INTER_NEAREST)

        # binarize
        m = (mask > 0).astype(np.float32)
        y = torch.from_numpy(m).unsqueeze(0).float()  # (1,H,W)

        return x, y

import torchvision.transforms as T

cls_tf_train = T.Compose([
    T.RandomHorizontalFlip(p=0.5),
    T.RandomRotation(degrees=10),
])

cls_tf_eval = T.Compose([])

import random
import torch.nn.functional as F

def seg_augment(x, y):
    # x: (3,H,W), y: (1,H,W)
    if random.random() < 0.5:
        x = torch.flip(x, dims=[2])
        y = torch.flip(y, dims=[2])
    # small rotation (approx via affine grid) — optional; keep off if you want stability
    return x, y

import torch
import torch.nn as nn
import torchvision.models as models

class MultiTaskNet(nn.Module):
    def __init__(self, num_classes=4):
        super().__init__()

        backbone = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)

        self.stem = nn.Sequential(
            backbone.conv1, backbone.bn1, backbone.relu, backbone.maxpool
        )
        self.layer1 = backbone.layer1
        self.layer2 = backbone.layer2
        self.layer3 = backbone.layer3
        self.layer4 = backbone.layer4

        self.avgpool = nn.AdaptiveAvgPool2d(1)
        self.cls_fc = nn.Linear(512, num_classes)

        # produce logits at a coarse resolution first
        self.seg_head = nn.Sequential(
            nn.Conv2d(512, 256, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 128, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 1, 1)  # logits (B,1,h,w)
        )

    def forward(self, x, task="both"):
        in_h, in_w = x.shape[-2], x.shape[-1]  # <-- input spatial size

        x = self.stem(x)
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        feats = self.layer4(x)

        out = {}

        if task in ["cls", "both"]:
            pooled = self.avgpool(feats).flatten(1)
            out["cls_logits"] = self.cls_fc(pooled)

        if task in ["seg", "both"]:
            seg_logits = self.seg_head(feats)  # coarse logits
            # <-- resize logits to match input mask size (e.g., 256x256)
            seg_logits = F.interpolate(seg_logits, size=(in_h, in_w), mode="bilinear", align_corners=False)
            out["seg_logits"] = seg_logits

        return out

import torch.nn.functional as F

cls_criterion = nn.CrossEntropyLoss()

def dice_loss(logits, targets, eps=1e-6):
    probs = torch.sigmoid(logits)
    num = 2 * (probs * targets).sum(dim=(2,3)) + eps
    den = (probs + targets).sum(dim=(2,3)) + eps
    dice = 1 - (num / den)
    return dice.mean()

def seg_loss(logits, targets):
    bce = F.binary_cross_entropy_with_logits(logits, targets)
    d = dice_loss(logits, targets)
    return 0.5*bce + 0.5*d

!pip install timm shap lime

from itertools import cycle

device = "cuda" if torch.cuda.is_available() else "cpu"
model = MultiTaskNet(num_classes=4).to(device)

optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)

# loaders
cls_train_ds = BRISCClassificationDataset(cls_train_samples, img_size=224)
cls_train_loader = DataLoader(cls_train_ds, batch_size=16, shuffle=True, num_workers=0)

seg_train_ds = BRISCSegmentationDataset(seg_train_pairs, img_size=256)
seg_train_loader = DataLoader(seg_train_ds, batch_size=8, shuffle=True, num_workers=0)

def train_one_epoch(model, cls_loader, seg_loader, alpha=1.0, beta=1.0):
    model.train()
    cls_iter = cycle(cls_loader)
    seg_iter = cycle(seg_loader)

    steps = min(len(cls_loader), len(seg_loader))  # balanced
    total_cls, total_seg = 0.0, 0.0

    for step in range(steps):
        # ---- classification step ----
        x, y = next(cls_iter)
        x, y = x.to(device), y.to(device)

        # optional: apply light aug (tensor-safe)
        # (If you want stronger aug, we can switch to Albumentations later)

        out = model(x, task="cls")
        loss_cls = cls_criterion(out["cls_logits"], y)

        optimizer.zero_grad(set_to_none=True)
        (alpha * loss_cls).backward()
        optimizer.step()
        total_cls += loss_cls.item()

        # ---- segmentation step ----
        xs, ys = next(seg_iter)
        xs, ys = xs.to(device), ys.to(device)

        # optional paired augmentation
        # (kept minimal here; can be improved)
        out = model(xs, task="seg")
        loss_s = seg_loss(out["seg_logits"], ys)

        optimizer.zero_grad(set_to_none=True)
        (beta * loss_s).backward()
        optimizer.step()
        total_seg += loss_s.item()

    return total_cls/steps, total_seg/steps

# run 1 epoch as a test
cls_l, seg_l = train_one_epoch(model, cls_train_loader, seg_train_loader)
print("Train losses | cls:", cls_l, "seg:", seg_l)

import matplotlib.pyplot as plt

model.eval()
xs, ys = next(iter(seg_train_loader))
xs, ys = xs.to(device), ys.to(device)

with torch.no_grad():
    out = model(xs, task="seg")
    pred = torch.sigmoid(out["seg_logits"])

# show first sample
img = xs[0].detach().cpu().permute(1,2,0).numpy()
gt  = ys[0].detach().cpu().squeeze(0).numpy()
pm  = pred[0].detach().cpu().squeeze(0).numpy()

plt.figure(figsize=(12,4))
plt.subplot(1,3,1); plt.imshow(img); plt.title("Image"); plt.axis("off")
plt.subplot(1,3,2); plt.imshow(gt, cmap="gray"); plt.title("GT Mask"); plt.axis("off")
plt.subplot(1,3,3); plt.imshow(img); plt.imshow(pm>0.5, alpha=0.4); plt.title("Pred Overlay"); plt.axis("off")
plt.tight_layout()
plt.show()

import torch

IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)
IMAGENET_STD  = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)

def denorm_rgb(x):
    """
    x: torch tensor (3,H,W), normalized with ImageNet mean/std
    returns: float RGB tensor in [0,1]
    """
    x = x.detach().cpu()
    x = x * IMAGENET_STD + IMAGENET_MEAN
    return x.clamp(0, 1)

import matplotlib.pyplot as plt
import numpy as np
import torch

IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)
IMAGENET_STD  = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)

def denorm_img(x):
    x = x.cpu()
    x = x * IMAGENET_STD + IMAGENET_MEAN
    return x.clamp(0, 1)

@torch.no_grad()
def show_seg_overlay(model, dataset, device, n=3, thr=0.5):
    model.eval()
    idxs = np.random.choice(len(dataset), size=min(n, len(dataset)), replace=False)

    for idx in idxs:
        x, y = dataset[idx]
        x_in = x.unsqueeze(0).to(device)

        out = model(x_in, task="seg")
        prob = torch.sigmoid(out["seg_logits"])[0,0].cpu().numpy()
        pred = (prob > thr).astype(np.uint8)

        # De-normalize for display
        img = denorm_img(x).permute(1,2,0).numpy()

        gt = y[0].cpu().numpy().astype(np.uint8)

        # overlay mask (yellow)
        overlay = img.copy()
        overlay[pred == 1] = overlay[pred == 1] * 0.5 + np.array([1.0, 1.0, 0.0]) * 0.5

        plt.figure(figsize=(12,4))
        plt.subplot(1,3,1); plt.title("Image (denorm)"); plt.imshow(img); plt.axis("off")
        plt.subplot(1,3,2); plt.title("GT Mask"); plt.imshow(gt, cmap="gray"); plt.axis("off")
        plt.subplot(1,3,3); plt.title("Pred Overlay"); plt.imshow(overlay); plt.axis("off")
        plt.show()

show_seg_overlay(model, seg_val_ds, device, n=5, thr=0.5)

import matplotlib.pyplot as plt
import numpy as np
import torch

IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)
IMAGENET_STD  = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)

def denorm_rgb(x):
    x = x.detach().cpu()
    x = x * IMAGENET_STD + IMAGENET_MEAN
    return x.clamp(0, 1)

@torch.no_grad()
def show_seg_overlay_color(model, dataset, device, n=3, thr=0.5, alpha=0.45):
    model.eval()
    idxs = np.random.choice(len(dataset), size=min(n, len(dataset)), replace=False)

    for idx in idxs:
        x, y = dataset[idx]
        x_in = x.unsqueeze(0).to(device)

        out = model(x_in, task="seg")
        prob = torch.sigmoid(out["seg_logits"])[0,0].detach().cpu().numpy()
        pred = (prob > thr).astype(np.uint8)
        gt = y[0].detach().cpu().numpy().astype(np.uint8)

        # Base image (denorm) -> still looks grayscale because MRI is grayscale
        img = denorm_rgb(x).permute(1,2,0).numpy()

        # Make a colorful overlay:
        # Pred mask in RED, GT mask in GREEN (optional)
        overlay_pred = img.copy()
        overlay_gt   = img.copy()

        red = np.array([1.0, 0.0, 0.0], dtype=np.float32)
        green = np.array([0.0, 1.0, 0.0], dtype=np.float32)

        overlay_pred[pred == 1] = (1 - alpha) * overlay_pred[pred == 1] + alpha * red
        overlay_gt[gt == 1]     = (1 - alpha) * overlay_gt[gt == 1]     + alpha * green

        plt.figure(figsize=(14,4))
        plt.subplot(1,4,1); plt.title("Image"); plt.imshow(img); plt.axis("off")
        plt.subplot(1,4,2); plt.title("GT (green)"); plt.imshow(overlay_gt); plt.axis("off")
        plt.subplot(1,4,3); plt.title(f"Pred (red) thr={thr}"); plt.imshow(overlay_pred); plt.axis("off")

        # Combined overlay: GT green + Pred red
        combined = img.copy()
        combined[gt == 1]   = (1 - alpha) * combined[gt == 1]   + alpha * green
        combined[pred == 1] = (1 - alpha) * combined[pred == 1] + alpha * red
        plt.subplot(1,4,4); plt.title("GT+Pred"); plt.imshow(combined); plt.axis("off")

        plt.show()

show_seg_overlay_color(model, seg_val_ds, device, n=5, thr=0.5, alpha=0.5)

@torch.no_grad()
def show_seg_heatmap(model, dataset, device, n=3):
    model.eval()
    idxs = np.random.choice(len(dataset), size=min(n, len(dataset)), replace=False)

    for idx in idxs:
        x, y = dataset[idx]
        x_in = x.unsqueeze(0).to(device)

        out = model(x_in, task="seg")
        prob = torch.sigmoid(out["seg_logits"])[0,0].detach().cpu().numpy()
        gt = y[0].detach().cpu().numpy()

        img = denorm_rgb(x).permute(1,2,0).numpy()

        plt.figure(figsize=(14,4))
        plt.subplot(1,3,1); plt.title("Image"); plt.imshow(img); plt.axis("off")
        plt.subplot(1,3,2); plt.title("GT Mask"); plt.imshow(gt, cmap="gray"); plt.axis("off")

        plt.subplot(1,3,3); plt.title("Prob Heatmap (jet)")
        plt.imshow(img)
        plt.imshow(prob, cmap="jet", alpha=0.45)   # <-- colorful overlay
        plt.axis("off")
        plt.show()

show_seg_heatmap(model, seg_val_ds, device, n=5)

import os, glob, random
import numpy as np
from PIL import Image

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as T
import torchvision.models as models

DATA_ROOT = "/kaggle/input/brisc2025/brisc2025"

CLS_TRAIN_DIR = os.path.join(DATA_ROOT, "classification_task", "train")
CLS_TEST_DIR  = os.path.join(DATA_ROOT, "classification_task", "test")

SEG_TRAIN_IMG_DIR  = os.path.join(DATA_ROOT, "segmentation_task", "train", "images")
SEG_TRAIN_MASK_DIR = os.path.join(DATA_ROOT, "segmentation_task", "train", "masks")
SEG_TEST_IMG_DIR   = os.path.join(DATA_ROOT, "segmentation_task", "test", "images")
SEG_TEST_MASK_DIR  = os.path.join(DATA_ROOT, "segmentation_task", "test", "masks")

print("CLS train exists:", os.path.isdir(CLS_TRAIN_DIR))
print("SEG train images exists:", os.path.isdir(SEG_TRAIN_IMG_DIR))

def build_seg_pairs(img_dir, mask_dir):
    img_paths = sorted(glob.glob(os.path.join(img_dir, "*")))
    mask_paths = sorted(glob.glob(os.path.join(mask_dir, "*")))

    # map by filename stem (without extension)
    def stem(p):
        return os.path.splitext(os.path.basename(p))[0]

    mask_map = {stem(p): p for p in mask_paths}
    pairs = []
    missing = 0

    for ip in img_paths:
        s = stem(ip)
        mp = mask_map.get(s, None)
        if mp is None:
            missing += 1
            continue
        pairs.append((ip, mp))

    print(f"Seg pairs: {len(pairs)} | missing masks for {missing} images")
    return pairs

seg_train_pairs = build_seg_pairs(SEG_TRAIN_IMG_DIR, SEG_TRAIN_MASK_DIR)
seg_test_pairs  = build_seg_pairs(SEG_TEST_IMG_DIR, SEG_TEST_MASK_DIR)

from torchvision.datasets import ImageFolder
from torch.utils.data import Subset

IMG_SIZE = 256

# Classification transforms
cls_train_tfms = T.Compose([
    T.Resize((IMG_SIZE, IMG_SIZE)),
    T.RandomHorizontalFlip(),
    T.ToTensor(),
    T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),
])

cls_val_tfms = T.Compose([
    T.Resize((IMG_SIZE, IMG_SIZE)),
    T.ToTensor(),
    T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),
])

# Build two views of the SAME folder, one with aug, one without
cls_full_train = ImageFolder(CLS_TRAIN_DIR, transform=cls_train_tfms)
cls_full_val   = ImageFolder(CLS_TRAIN_DIR, transform=cls_val_tfms)

# Split indices
indices = np.arange(len(cls_full_train))
np.random.seed(42)
np.random.shuffle(indices)

split = int(0.8 * len(indices))
train_idx, val_idx = indices[:split], indices[split:]

cls_train_ds = Subset(cls_full_train, train_idx)
cls_val_ds   = Subset(cls_full_val,   val_idx)

print("Classes:", cls_full_train.classes)
print("CLS Train:", len(cls_train_ds), "| CLS Val:", len(cls_val_ds))

seg_train_ds = BRISCSegmentationDataset(seg_train_pairs, img_size=IMG_SIZE)
seg_val_ds   = BRISCSegmentationDataset(seg_test_pairs,  img_size=IMG_SIZE)

BATCH_CLS = 24
BATCH_SEG = 8

cls_train_loader = DataLoader(cls_train_ds, batch_size=BATCH_CLS, shuffle=True,  num_workers=2, pin_memory=True)
cls_val_loader   = DataLoader(cls_val_ds,   batch_size=BATCH_CLS, shuffle=False, num_workers=2, pin_memory=True)

seg_train_loader = DataLoader(seg_train_ds, batch_size=BATCH_SEG, shuffle=True,  num_workers=2, pin_memory=True)
seg_val_loader   = DataLoader(seg_val_ds,   batch_size=BATCH_SEG, shuffle=False, num_workers=2, pin_memory=True)

class ConvBlock(nn.Module):
    def __init__(self, in_ch, out_ch):
        super().__init__()
        self.block = nn.Sequential(
            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),
            nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True),
        )

    def forward(self, x):
        return self.block(x)

class UpBlock(nn.Module):
    def __init__(self, in_ch, skip_ch, out_ch):
        super().__init__()
        self.conv = ConvBlock(in_ch + skip_ch, out_ch)

    def forward(self, x, skip):
        x = F.interpolate(x, size=skip.shape[-2:], mode="bilinear", align_corners=False)
        x = torch.cat([x, skip], dim=1)
        return self.conv(x)

class MultiTaskNet(nn.Module):
    def __init__(self, num_classes=4, dropout=0.2):
        super().__init__()
        enc = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)

        self.stem = nn.Sequential(enc.conv1, enc.bn1, enc.relu)   # /2
        self.maxpool = enc.maxpool                                # /4
        self.layer1 = enc.layer1                                   # /4  (64)
        self.layer2 = enc.layer2                                   # /8  (128)
        self.layer3 = enc.layer3                                   # /16 (256)
        self.layer4 = enc.layer4                                   # /32 (512)

        # Classification head
        self.cls_pool = nn.AdaptiveAvgPool2d(1)
        self.cls_drop = nn.Dropout(dropout)
        self.cls_head = nn.Linear(512, num_classes)

        # Segmentation decoder (U-Net style)
        self.up3 = UpBlock(in_ch=512, skip_ch=256, out_ch=256)  # /16
        self.up2 = UpBlock(in_ch=256, skip_ch=128, out_ch=128)  # /8
        self.up1 = UpBlock(in_ch=128, skip_ch=64,  out_ch=64)   # /4

        self.seg_out = nn.Conv2d(64, 1, kernel_size=1)

    def forward(self, x, task="both"):
        out = {}

        x0 = self.stem(x)           # /2
        x1 = self.maxpool(x0)       # /4
        c1 = self.layer1(x1)        # /4 (64)
        c2 = self.layer2(c1)        # /8 (128)
        c3 = self.layer3(c2)        # /16 (256)
        c4 = self.layer4(c3)        # /32 (512)

        if task in ["cls", "both"]:
            pooled = self.cls_pool(c4).flatten(1)
            pooled = self.cls_drop(pooled)
            out["cls_logits"] = self.cls_head(pooled)

        if task in ["seg", "both"]:
            d3 = self.up3(c4, c3)   # /16
            d2 = self.up2(d3, c2)   # /8
            d1 = self.up1(d2, c1)   # /4

            seg_logits = self.seg_out(d1)  # /4
            seg_logits = F.interpolate(seg_logits, size=x.shape[-2:], mode="bilinear", align_corners=False)
            out["seg_logits"] = seg_logits

        return out

device = "cuda" if torch.cuda.is_available() else "cpu"
model = MultiTaskNet(num_classes=len(cls_full_train.classes)).to(device)

class DiceLoss(nn.Module):
    def __init__(self, eps=1e-6):
        super().__init__()
        self.eps = eps

    def forward(self, logits, targets):
        probs = torch.sigmoid(logits)
        probs = probs.view(probs.size(0), -1)
        targets = targets.view(targets.size(0), -1)

        inter = (probs * targets).sum(dim=1)
        union = probs.sum(dim=1) + targets.sum(dim=1)
        dice = (2*inter + self.eps) / (union + self.eps)
        return 1 - dice.mean()

cls_criterion = nn.CrossEntropyLoss()
bce_criterion = nn.BCEWithLogitsLoss()
dice_criterion = DiceLoss()

def seg_loss_fn(seg_logits, seg_targets, alpha=0.5):
    return alpha * bce_criterion(seg_logits, seg_targets) + (1-alpha) * dice_criterion(seg_logits, seg_targets)

from itertools import cycle

def train_one_epoch(model, cls_loader, seg_loader, optimizer, device,
                    seg_alpha=0.5, lambda_seg=0.6, seg_every=2):
    model.train()
    total_cls, total_seg = 0.0, 0.0
    n_cls, n_seg = 0, 0

    seg_iter = cycle(seg_loader)

    for step, (x_cls, y_cls) in enumerate(cls_loader, start=1):
        # ---- classification step ----
        x_cls = x_cls.to(device, non_blocking=True)
        y_cls = y_cls.to(device, non_blocking=True)

        out = model(x_cls, task="cls")
        loss_cls = cls_criterion(out["cls_logits"], y_cls)

        optimizer.zero_grad(set_to_none=True)
        loss_cls.backward()
        optimizer.step()

        total_cls += loss_cls.item() * x_cls.size(0)
        n_cls += x_cls.size(0)

        # ---- segmentation step (less frequent) ----
        if step % seg_every == 0:
            x_seg, y_seg = next(seg_iter)
            x_seg = x_seg.to(device, non_blocking=True)
            y_seg = y_seg.to(device, non_blocking=True)

            out = model(x_seg, task="seg")
            loss_seg = seg_loss_fn(out["seg_logits"], y_seg, alpha=seg_alpha) * lambda_seg

            optimizer.zero_grad(set_to_none=True)
            loss_seg.backward()
            optimizer.step()

            total_seg += loss_seg.item() * x_seg.size(0)
            n_seg += x_seg.size(0)

    return (total_cls / max(n_cls,1)), (total_seg / max(n_seg,1))

@torch.no_grad()
def validate_classification(model, loader, device):
    model.eval()
    total_loss = 0.0
    correct = 0
    total = 0

    for x, y in loader:
        x = x.to(device, non_blocking=True)
        y = y.to(device, non_blocking=True)

        out = model(x, task="cls")
        logits = out["cls_logits"]
        loss = cls_criterion(logits, y)

        total_loss += loss.item() * x.size(0)
        preds = logits.argmax(dim=1)
        correct += (preds == y).sum().item()
        total += x.size(0)

    return (total_loss / max(total, 1)), (correct / max(total, 1))

@torch.no_grad()
def validate_segmentation(
    model,
    loader,
    device,
    seg_alpha=0.5,
    thresholds=(0.3, 0.4, 0.5, 0.6, 0.7)
):
    model.eval()
    total_loss = 0.0
    total = 0

    dice_sums = {t: 0.0 for t in thresholds}
    iou_sums  = {t: 0.0 for t in thresholds}

    eps = 1e-6

    for x, y in loader:
        x = x.to(device, non_blocking=True)
        y = y.to(device, non_blocking=True)

        out = model(x, task="seg")
        logits = out["seg_logits"]

        loss = seg_loss_fn(logits, y, alpha=seg_alpha)
        total_loss += loss.item() * x.size(0)

        probs = torch.sigmoid(logits)

        for t in thresholds:
            preds = (probs > t).float()

            inter = (preds * y).sum(dim=(1,2,3))
            union = preds.sum(dim=(1,2,3)) + y.sum(dim=(1,2,3))
            dice = (2*inter + eps) / (union + eps)

            denom = (preds + y - preds*y).sum(dim=(1,2,3)) + eps
            iou = (inter + eps) / denom

            dice_sums[t] += dice.mean().item() * x.size(0)
            iou_sums[t]  += iou.mean().item()  * x.size(0)

        total += x.size(0)

    avg_loss = total_loss / max(total, 1)
    avg_dice = {t: dice_sums[t] / max(total, 1) for t in thresholds}
    avg_iou  = {t: iou_sums[t]  / max(total, 1) for t in thresholds}

    # ⭐ Find best threshold by Dice
    best_t = max(avg_dice, key=lambda k: avg_dice[k])
    best_dice = avg_dice[best_t]
    best_iou  = avg_iou[best_t]

    return avg_loss, avg_dice, avg_iou, best_t, best_dice, best_iou

import os

def fit(model,
        cls_train_loader, cls_val_loader,
        seg_train_loader, seg_val_loader,
        optimizer,
        device,
        epochs=10,
        seg_alpha=0.5,
        lambda_seg=1.0,
        save_path="multitask_best.pt"):

    best_score = -1e9
    history = []

    for epoch in range(1, epochs+1):
        train_cls_loss, train_seg_loss = train_one_epoch(
            model, cls_train_loader, seg_train_loader, optimizer, device,
            seg_alpha=seg_alpha, lambda_seg=lambda_seg
        )

        val_cls_loss, val_cls_acc = validate_classification(
            model, cls_val_loader, device
        )

        val_seg_loss, val_seg_dice_dict, val_seg_iou_dict, best_t, best_dice, best_iou = validate_segmentation(
            model,
            seg_val_loader,
            device,
            seg_alpha=seg_alpha,
            thresholds=(0.3, 0.4, 0.5, 0.6, 0.7)
        )

        # Choose a default threshold for scoring (keep 0.5 as standard)
        val_seg_dice = val_seg_dice_dict[0.5]
        val_seg_iou  = val_seg_iou_dict[0.5]

        # Combined score: prioritize Dice and Acc
        score = (val_cls_acc * 0.6) + (val_seg_dice * 0.4)

        scheduler.step(score)

        history.append({
            "epoch": epoch,
            "train_cls_loss": train_cls_loss,
            "train_seg_loss": train_seg_loss,
            "val_cls_loss": val_cls_loss,
            "val_cls_acc": val_cls_acc,
            "val_seg_loss": val_seg_loss,
            "val_seg_dice": val_seg_dice,
            "val_seg_iou": val_seg_iou,
            "score": score
        })

        print(
            f"Epoch {epoch:02d} | "
            f"Train: cls_loss={train_cls_loss:.4f}, seg_loss={train_seg_loss:.4f} | "
            f"Val: cls_loss={val_cls_loss:.4f}, acc={val_cls_acc:.4f} | "
            f"seg_loss={val_seg_loss:.4f} | "
            f"dice@0.3={val_seg_dice_dict[0.3]:.4f}, "
            f"dice@0.5={val_seg_dice_dict[0.5]:.4f}, "
            f"dice@0.7={val_seg_dice_dict[0.7]:.4f} | "
            f"BEST: t={best_t:.2f}, dice={best_dice:.4f}, iou={best_iou:.4f} | "
            f"score={score:.4f}"
        )

        if score > best_score:
            best_score = score
            torch.save({
                "model_state_dict": model.state_dict(),
                "optimizer_state_dict": optimizer.state_dict(),
                "epoch": epoch,
                "best_score": best_score,
                "classes": getattr(cls_train_loader.dataset, "classes", None)
            }, save_path)
            print(f"  -> Saved best checkpoint: {save_path} (score={best_score:.4f})")

    return history


# optimizer
optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, mode="max", factor=0.5, patience=2
)

history = fit(
    model,
    cls_train_loader, cls_val_loader,
    seg_train_loader, seg_val_loader,
    optimizer,
    device,
    epochs=15,
    seg_alpha=0.5,
    lambda_seg=0.3,
    save_path="multitask_best.pt"
)

ckpt = torch.load("multitask_best.pt", map_location=device)
model.load_state_dict(ckpt["model_state_dict"])
print("Loaded checkpoint from epoch:", ckpt["epoch"], "| best_score:", ckpt["best_score"])

import matplotlib.pyplot as plt

@torch.no_grad()
def show_seg_predictions(model, dataset, device, best_t=0.5, n=5):
    model.eval()
    idxs = np.random.choice(len(dataset), size=min(n, len(dataset)), replace=False)

    for idx in idxs:
        x, y = dataset[idx]
        x_in = x.unsqueeze(0).to(device)
        out = model(x_in, task="seg")
        prob = torch.sigmoid(out["seg_logits"])[0,0].cpu().numpy()
        pred = (prob > best_t).astype(np.uint8)

        img = denorm_rgb(x).permute(1,2,0).numpy()

        # de-normalize if you normalized seg images later; currently seg images are [0,1] so OK

        gt = y[0].cpu().numpy().astype(np.uint8)

        plt.figure(figsize=(12,4))
        plt.subplot(1,3,1); plt.title("Image"); plt.imshow(img); plt.axis("off")
        plt.subplot(1,3,2); plt.title("GT Mask"); plt.imshow(gt, cmap="gray"); plt.axis("off")
        plt.subplot(1,3,3); plt.title("Pred Mask"); plt.imshow(pred, cmap="gray"); plt.axis("off")
        plt.show()

show_seg_predictions(model, seg_val_ds, device, n=5)

from sklearn.metrics import classification_report, confusion_matrix

@torch.no_grad()
def get_cls_preds(model, loader, device):
    model.eval()
    y_true, y_pred = [], []
    for x, y in loader:
        x = x.to(device, non_blocking=True)
        out = model(x, task="cls")
        preds = out["cls_logits"].argmax(dim=1).cpu().numpy()
        y_pred.extend(preds.tolist())
        y_true.extend(y.numpy().tolist())
    return np.array(y_true), np.array(y_pred)

y_true, y_pred = get_cls_preds(model, cls_val_loader, device)
target_names = cls_full_train.classes
print(classification_report(y_true, y_pred, target_names=target_names))
print("Confusion Matrix:\n", confusion_matrix(y_true, y_pred))

import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix

# y_true, y_pred already computed
cm = confusion_matrix(y_true, y_pred)
class_names = cls_full_train.classes  # IMPORTANT: use ImageFolder classes

plt.figure(figsize=(6, 5))
plt.imshow(cm, interpolation="nearest", cmap=plt.cm.Blues)
plt.title("Confusion Matrix")
plt.colorbar()

tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names, rotation=45, ha="right")
plt.yticks(tick_marks, class_names)

# Annotate cells
thresh = cm.max() / 2.0
for i in range(cm.shape[0]):
    for j in range(cm.shape[1]):
        plt.text(
            j, i, format(cm[i, j], "d"),
            ha="center", va="center",
            color="white" if cm[i, j] > thresh else "black"
        )

plt.ylabel("True Label")
plt.xlabel("Predicted Label")
plt.tight_layout()
plt.show()

cm_norm = cm.astype("float") / cm.sum(axis=1, keepdims=True)

plt.figure(figsize=(6, 5))
plt.imshow(cm_norm, interpolation="nearest", cmap=plt.cm.Blues)
plt.title("Normalized Confusion Matrix")
plt.colorbar()

plt.xticks(tick_marks, class_names, rotation=45, ha="right")
plt.yticks(tick_marks, class_names)

for i in range(cm_norm.shape[0]):
    for j in range(cm_norm.shape[1]):
        plt.text(
            j, i, f"{cm_norm[i, j]:.2f}",
            ha="center", va="center",
            color="white" if cm_norm[i, j] > 0.5 else "black"
        )

plt.ylabel("True Label")
plt.xlabel("Predicted Label")
plt.tight_layout()
plt.show()

import numpy as np
import matplotlib.pyplot as plt

def hist_get(history, key, default=np.nan):
    return np.array([h.get(key, default) for h in history], dtype=float)

epochs = np.arange(1, len(history)+1)

train_cls_loss = hist_get(history, "train_cls_loss")
val_cls_loss   = hist_get(history, "val_cls_loss")
val_cls_acc    = hist_get(history, "val_cls_acc")

plt.figure(figsize=(7,4))
plt.plot(epochs, train_cls_loss, label="Train cls loss")
plt.plot(epochs, val_cls_loss, label="Val cls loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Classification Loss Curves")
plt.legend()
plt.tight_layout()
plt.show()

plt.figure(figsize=(7,4))
plt.plot(epochs, val_cls_acc, label="Val accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.title("Classification Accuracy Curve")
plt.legend()
plt.tight_layout()
plt.show()

train_seg_loss = hist_get(history, "train_seg_loss")
val_seg_loss   = hist_get(history, "val_seg_loss")
val_seg_dice   = hist_get(history, "val_seg_dice")  # if present
val_seg_iou    = hist_get(history, "val_seg_iou")   # if present

plt.figure(figsize=(7,4))
plt.plot(epochs, train_seg_loss, label="Train seg loss")
plt.plot(epochs, val_seg_loss, label="Val seg loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Segmentation Loss Curves")
plt.legend()
plt.tight_layout()
plt.show()

if not np.isnan(val_seg_dice).all():
    plt.figure(figsize=(7,4))
    plt.plot(epochs, val_seg_dice, label="Val Dice")
    plt.xlabel("Epoch")
    plt.ylabel("Dice")
    plt.title("Segmentation Dice Curve")
    plt.legend()
    plt.tight_layout()
    plt.show()

if not np.isnan(val_seg_iou).all():
    plt.figure(figsize=(7,4))
    plt.plot(epochs, val_seg_iou, label="Val IoU")
    plt.xlabel("Epoch")
    plt.ylabel("IoU")
    plt.title("Segmentation IoU Curve")
    plt.legend()
    plt.tight_layout()
    plt.show()

from sklearn.metrics import confusion_matrix

def plot_confusion_matrix(cm, class_names, title="Confusion Matrix"):
    plt.figure(figsize=(6,5))
    plt.imshow(cm, interpolation="nearest", cmap=plt.cm.Blues)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(class_names))
    plt.xticks(tick_marks, class_names, rotation=45, ha="right")
    plt.yticks(tick_marks, class_names)

    thresh = cm.max() / 2.0
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            plt.text(j, i, f"{cm[i,j]:d}",
                     ha="center", va="center",
                     color="white" if cm[i,j] > thresh else "black")
    plt.ylabel("True Label")
    plt.xlabel("Predicted Label")
    plt.tight_layout()
    plt.show()

def plot_confusion_matrix_norm(cm, class_names, title="Normalized Confusion Matrix"):
    cmn = cm.astype(float) / cm.sum(axis=1, keepdims=True)
    plt.figure(figsize=(6,5))
    plt.imshow(cmn, interpolation="nearest", cmap=plt.cm.Blues)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(class_names))
    plt.xticks(tick_marks, class_names, rotation=45, ha="right")
    plt.yticks(tick_marks, class_names)

    for i in range(cmn.shape[0]):
        for j in range(cmn.shape[1]):
            plt.text(j, i, f"{cmn[i,j]:.2f}", ha="center", va="center",
                     color="white" if cmn[i,j] > 0.5 else "black")
    plt.ylabel("True Label")
    plt.xlabel("Predicted Label")
    plt.tight_layout()
    plt.show()

class_names = cls_full_train.classes
cm = confusion_matrix(y_true, y_pred)
plot_confusion_matrix(cm, class_names)
plot_confusion_matrix_norm(cm, class_names)

from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc

@torch.no_grad()
def get_cls_probs(model, loader, device):
    model.eval()
    all_probs = []
    all_y = []
    for x, y in loader:
        x = x.to(device, non_blocking=True)
        out = model(x, task="cls")
        probs = torch.softmax(out["cls_logits"], dim=1).cpu().numpy()
        all_probs.append(probs)
        all_y.append(y.numpy())
    return np.concatenate(all_y), np.concatenate(all_probs)

y_true, y_prob = get_cls_probs(model, cls_val_loader, device)
class_names = cls_full_train.classes
n_classes = len(class_names)

Y = label_binarize(y_true, classes=np.arange(n_classes))

plt.figure(figsize=(7,5))
for i in range(n_classes):
    fpr, tpr, _ = roc_curve(Y[:, i], y_prob[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f"{class_names[i]} (AUC={roc_auc:.3f})")

plt.plot([0,1], [0,1], linestyle="--")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curves (One-vs-Rest)")
plt.legend()
plt.tight_layout()
plt.show()

from sklearn.metrics import precision_recall_curve, average_precision_score

plt.figure(figsize=(7,5))
for i in range(n_classes):
    precision, recall, _ = precision_recall_curve(Y[:, i], y_prob[:, i])
    ap = average_precision_score(Y[:, i], y_prob[:, i])
    plt.plot(recall, precision, label=f"{class_names[i]} (AP={ap:.3f})")

plt.xlabel("Recall")
plt.ylabel("Precision")
plt.title("Precision–Recall Curves (One-vs-Rest)")
plt.legend()
plt.tight_layout()
plt.show()

y_conf = y_prob.max(axis=1)
y_pred = y_prob.argmax(axis=1)
correct = (y_pred == y_true)

plt.figure(figsize=(7,4))
plt.hist(y_conf[correct], bins=20, alpha=0.7, label="Correct")
plt.hist(y_conf[~correct], bins=20, alpha=0.7, label="Incorrect")
plt.xlabel("Max Softmax Probability")
plt.ylabel("Count")
plt.title("Prediction Confidence Histogram")
plt.legend()
plt.tight_layout()
plt.show()

import torch
import numpy as np
import matplotlib.pyplot as plt

IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)
IMAGENET_STD  = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)

def denorm_rgb(x):
    x = x.detach().cpu()
    x = x * IMAGENET_STD + IMAGENET_MEAN
    return x.clamp(0, 1)

@torch.no_grad()
def show_misclassified(model, loader, device, class_names, max_show=12):
    model.eval()
    shown = 0
    plt.figure(figsize=(12,8))

    for x, y in loader:
        x = x.to(device, non_blocking=True)
        out = model(x, task="cls")
        probs = torch.softmax(out["cls_logits"], dim=1)
        pred = probs.argmax(dim=1).cpu().numpy()
        conf = probs.max(dim=1).values.cpu().numpy()
        y_np = y.numpy()

        for i in range(len(y_np)):
            if pred[i] != y_np[i]:
                img = denorm_rgb(x[i].cpu()).permute(1,2,0).numpy()
                plt.subplot(3, 4, shown+1)
                plt.imshow(img)
                plt.axis("off")
                plt.title(f"T:{class_names[y_np[i]]}\nP:{class_names[pred[i]]} ({conf[i]:.2f})")
                shown += 1
                if shown >= max_show:
                    plt.tight_layout()
                    plt.show()
                    return

    plt.tight_layout()
    plt.show()

show_misclassified(model, cls_val_loader, device, cls_full_train.classes, max_show=12)

import numpy as np
import matplotlib.pyplot as plt
import torch

@torch.no_grad()
def show_seg_heatmap_and_overlay(model, dataset, device, n=5, thr=0.5, alpha=0.45):
    model.eval()
    idxs = np.random.choice(len(dataset), size=min(n, len(dataset)), replace=False)

    for idx in idxs:
        x, y = dataset[idx]
        x_in = x.unsqueeze(0).to(device)

        out = model(x_in, task="seg")
        prob = torch.sigmoid(out["seg_logits"])[0,0].cpu().numpy()
        pred = (prob > thr).astype(np.uint8)
        gt = y[0].cpu().numpy().astype(np.uint8)

        img = denorm_rgb(x).permute(1,2,0).numpy()

        # Color overlays
        overlay_pred = img.copy()
        red = np.array([1.0, 0.0, 0.0], dtype=np.float32)
        overlay_pred[pred == 1] = (1-alpha)*overlay_pred[pred == 1] + alpha*red

        plt.figure(figsize=(14,4))
        plt.subplot(1,4,1); plt.title("Image"); plt.imshow(img); plt.axis("off")
        plt.subplot(1,4,2); plt.title("GT Mask"); plt.imshow(gt, cmap="gray"); plt.axis("off")
        plt.subplot(1,4,3); plt.title(f"Pred Overlay (thr={thr})"); plt.imshow(overlay_pred); plt.axis("off")

        plt.subplot(1,4,4); plt.title("Prob Heatmap")
        plt.imshow(img)
        plt.imshow(prob, cmap="jet", alpha=0.45)
        plt.axis("off")
        plt.show()

# Example usage:
# show_seg_heatmap_and_overlay(model, seg_val_ds, device, n=5, thr=best_t)
show_seg_heatmap_and_overlay(model, seg_val_ds, device, n=5, thr=0.5)

@torch.no_grad()
def dice_at_threshold(model, loader, device, t=0.5):
    model.eval()
    eps = 1e-6
    total = 0
    dice_sum = 0.0

    for x, y in loader:
        x = x.to(device, non_blocking=True)
        y = y.to(device, non_blocking=True)

        out = model(x, task="seg")
        prob = torch.sigmoid(out["seg_logits"])
        pred = (prob > t).float()

        inter = (pred * y).sum(dim=(1,2,3))
        union = pred.sum(dim=(1,2,3)) + y.sum(dim=(1,2,3))
        dice = (2*inter + eps) / (union + eps)

        dice_sum += dice.mean().item() * x.size(0)
        total += x.size(0)

    return dice_sum / max(total,1)

ths = np.arange(0.1, 0.91, 0.05)
dice_scores = [dice_at_threshold(model, seg_val_loader, device, t=float(t)) for t in ths]

best_idx = int(np.argmax(dice_scores))
print("Best threshold:", ths[best_idx], "Best Dice:", dice_scores[best_idx])

plt.figure(figsize=(7,4))
plt.plot(ths, dice_scores, marker="o")
plt.xlabel("Threshold")
plt.ylabel("Dice")
plt.title("Dice vs Threshold (Validation)")
plt.tight_layout()
plt.show()

val_acc  = hist_get(history, "val_cls_acc")
val_dice = hist_get(history, "val_seg_dice")

plt.figure(figsize=(6,5))
plt.scatter(val_acc, val_dice)
for i, (a, d) in enumerate(zip(val_acc, val_dice), start=1):
    plt.text(a, d, str(i), fontsize=9)

plt.xlabel("Validation Accuracy (classification)")
plt.ylabel("Validation Dice (segmentation)")
plt.title("Task Interaction: Acc vs Dice Across Epochs")
plt.tight_layout()
plt.show()

import torch
import numpy as np
import matplotlib.pyplot as plt

IMAGENET_MEAN = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)
IMAGENET_STD  = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)

def denorm_rgb(x):
    x = x.detach().cpu()
    x = x * IMAGENET_STD + IMAGENET_MEAN
    return x.clamp(0, 1)

class GradCAM:
    def __init__(self, model, target_layer):
        self.model = model
        self.target_layer = target_layer
        self.activations = None
        self.gradients = None

        self.hook_a = target_layer.register_forward_hook(self._forward_hook)
        self.hook_g = target_layer.register_full_backward_hook(self._backward_hook)

    def _forward_hook(self, module, inp, out):
        self.activations = out  # (B,C,H,W)

    def _backward_hook(self, module, grad_input, grad_output):
        self.gradients = grad_output[0]  # (B,C,H,W)

    def remove(self):
        self.hook_a.remove()
        self.hook_g.remove()

    def __call__(self, x, class_idx=None):
        """
        x: (1,3,H,W) normalized
        class_idx: int or None (if None, use predicted class)
        returns: cam (H,W) in [0,1], pred_idx, pred_prob
        """
        self.model.eval()

        # Forward (classification task)
        out = self.model(x, task="cls")
        logits = out["cls_logits"]  # (1,num_classes)
        probs = torch.softmax(logits, dim=1)

        pred_idx = int(torch.argmax(probs, dim=1).item())
        pred_prob = float(probs[0, pred_idx].item())

        if class_idx is None:
            class_idx = pred_idx

        # Backward for selected class
        self.model.zero_grad(set_to_none=True)
        score = logits[0, class_idx]
        score.backward(retain_graph=True)

        # Compute CAM
        grads = self.gradients[0]       # (C,H,W)
        acts = self.activations[0]      # (C,H,W)

        weights = grads.mean(dim=(1,2)) # (C,)
        cam = (weights[:, None, None] * acts).sum(dim=0)  # (H,W)
        cam = torch.relu(cam)

        cam = cam - cam.min()
        cam = cam / (cam.max() + 1e-8)

        cam_np = cam.detach().cpu().numpy()
        return cam_np, pred_idx, pred_prob

import cv2

def show_gradcam_on_image(img_tensor, cam, title="", alpha=0.45):
    """
    img_tensor: (3,H,W) normalized tensor
    cam: (h,w) numpy in [0,1] (will be resized)
    """
    img = denorm_rgb(img_tensor).permute(1,2,0).numpy()  # [0,1]
    H, W = img.shape[:2]

    cam_resized = cv2.resize(cam, (W, H))
    cam_uint8 = np.uint8(255 * cam_resized)
    heatmap = cv2.applyColorMap(cam_uint8, cv2.COLORMAP_JET)  # BGR
    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB) / 255.0

    overlay = (1 - alpha) * img + alpha * heatmap
    overlay = np.clip(overlay, 0, 1)

    plt.figure(figsize=(12,4))
    plt.subplot(1,3,1); plt.title("Image"); plt.imshow(img); plt.axis("off")
    plt.subplot(1,3,2); plt.title("Grad-CAM Heatmap"); plt.imshow(heatmap); plt.axis("off")
    plt.subplot(1,3,3); plt.title(title); plt.imshow(overlay); plt.axis("off")
    plt.tight_layout()
    plt.show()

@torch.no_grad()
def grab_one_batch(loader):
    for x, y in loader:
        return x, y

# Create GradCAM object using the last encoder block
# If your model is MultiTaskNet with layer4:
cam_extractor = GradCAM(model, target_layer=model.layer4)

x_batch, y_batch = grab_one_batch(cls_val_loader)
x_batch = x_batch.to(device)

class_names = cls_full_train.classes

for i in range(min(5, x_batch.size(0))):
    x1 = x_batch[i:i+1]  # (1,3,H,W)
    cam, pred_idx, pred_prob = cam_extractor(x1, class_idx=None)
    title = f"Pred: {class_names[pred_idx]} ({pred_prob:.2f}) | True: {class_names[int(y_batch[i])]}"
    show_gradcam_on_image(x_batch[i].cpu(), cam, title=title, alpha=0.45)

# optional cleanup if you want:
# cam_extractor.remove()

@torch.no_grad()
def show_seg_error_maps(model, dataset, device, n=5, thr=0.5, alpha=0.55):
    model.eval()
    idxs = np.random.choice(len(dataset), size=min(n, len(dataset)), replace=False)

    for idx in idxs:
        x, y = dataset[idx]
        x_in = x.unsqueeze(0).to(device)

        out = model(x_in, task="seg")
        prob = torch.sigmoid(out["seg_logits"])[0,0].detach().cpu().numpy()
        pred = (prob > thr).astype(np.uint8)

        gt = y[0].detach().cpu().numpy().astype(np.uint8)

        # Compute TP/FP/FN
        tp = (pred == 1) & (gt == 1)
        fp = (pred == 1) & (gt == 0)
        fn = (pred == 0) & (gt == 1)

        img = denorm_rgb(x).permute(1,2,0).numpy()

        # Create RGB error overlay
        overlay = img.copy()
        green = np.array([0.0, 1.0, 0.0], dtype=np.float32)  # TP
        red   = np.array([1.0, 0.0, 0.0], dtype=np.float32)  # FP
        blue  = np.array([0.0, 0.0, 1.0], dtype=np.float32)  # FN

        overlay[tp] = (1-alpha)*overlay[tp] + alpha*green
        overlay[fp] = (1-alpha)*overlay[fp] + alpha*red
        overlay[fn] = (1-alpha)*overlay[fn] + alpha*blue

        plt.figure(figsize=(14,4))
        plt.subplot(1,4,1); plt.title("Image"); plt.imshow(img); plt.axis("off")
        plt.subplot(1,4,2); plt.title("GT Mask"); plt.imshow(gt, cmap="gray"); plt.axis("off")
        plt.subplot(1,4,3); plt.title(f"Pred Mask (thr={thr})"); plt.imshow(pred, cmap="gray"); plt.axis("off")
        plt.subplot(1,4,4); plt.title("Error Map: TP=Green, FP=Red, FN=Blue"); plt.imshow(overlay); plt.axis("off")
        plt.tight_layout()
        plt.show()

# If you have best_t from validation:
# show_seg_error_maps(model, seg_val_ds, device, n=5, thr=best_t)

show_seg_error_maps(model, seg_val_ds, device, n=5, thr=0.5)

